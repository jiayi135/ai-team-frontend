# Hugging Face èµ„æºæ¸…å•

æœ¬æ–‡æ¡£æ±‡æ€»äº†æ‰€æœ‰ä¸é¡¹ç›®ç›¸å…³çš„ Hugging Face èµ„æºï¼ŒåŒ…æ‹¬æ¨¡å‹ã€æ•°æ®é›†ã€Spaces å’Œè®ºæ–‡ï¼Œæ–¹ä¾¿å›¢é˜Ÿæˆå‘˜å¿«é€ŸæŸ¥æ‰¾å’Œä½¿ç”¨ã€‚

## è®¤è¯ä¿¡æ¯

**API Token**: è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® `HF_TOKEN`  
**è´¦å·é‚®ç®±**: huzhitao117@outlook.com  
**ä½¿ç”¨é™åˆ¶**: æ ¹æ® HF å…è´¹å±‚çº§é™åˆ¶

## æ¨èæ¨¡å‹

### å¯¹è¯å’Œæ–‡æœ¬ç”Ÿæˆæ¨¡å‹

#### Qwen/Qwen2.5-7B-Instruct â­ æ¨è

**åŸºæœ¬ä¿¡æ¯**:
- **æ¨¡å‹ ID**: `Qwen/Qwen2.5-7B-Instruct`
- **ä»»åŠ¡ç±»å‹**: text-generation
- **åº“**: transformers
- **ä¸‹è½½é‡**: 10.9M
- **ç‚¹èµæ•°**: 1059
- **è®¸å¯è¯**: Apache 2.0

**ç‰¹ç‚¹**:
- ä¸­ç­‰è§„æ¨¡ï¼Œæ€§èƒ½ä¼˜ç§€
- æ”¯æŒå¯¹è¯å’ŒæŒ‡ä»¤è·Ÿéš
- è‹±æ–‡æ”¯æŒè‰¯å¥½
- é€‚åˆä½œä¸ºä¸»è¦å¯¹è¯å¼•æ“

**ä½¿ç”¨åœºæ™¯**:
- AI ä»£ç†å¯¹è¯
- ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œ
- ä»£ç ç”Ÿæˆå’Œè§£é‡Š
- æ–‡æ¡£ç”Ÿæˆ

**é“¾æ¥**: [https://hf.co/Qwen/Qwen2.5-7B-Instruct](https://hf.co/Qwen/Qwen2.5-7B-Instruct)

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from huggingface_hub import InferenceClient
import os

client = InferenceClient(token=os.getenv('HF_TOKEN'))

response = client.text_generation(
    "Explain what is AI agent",
    model="Qwen/Qwen2.5-7B-Instruct",
    max_new_tokens=200
)
```

---

#### Qwen/Qwen3-0.6B âš¡ å¿«é€Ÿ

**åŸºæœ¬ä¿¡æ¯**:
- **æ¨¡å‹ ID**: `Qwen/Qwen3-0.6B`
- **ä»»åŠ¡ç±»å‹**: text-generation
- **åº“**: transformers
- **ä¸‹è½½é‡**: 9.6M
- **ç‚¹èµæ•°**: 1050
- **è®¸å¯è¯**: Apache 2.0

**ç‰¹ç‚¹**:
- è½»é‡çº§æ¨¡å‹ï¼ˆ600M å‚æ•°ï¼‰
- å“åº”é€Ÿåº¦å¿«
- èµ„æºæ¶ˆè€—ä½
- é€‚åˆå®æ—¶äº¤äº’

**ä½¿ç”¨åœºæ™¯**:
- å¿«é€Ÿå“åº”åœºæ™¯
- ç®€å•å¯¹è¯
- å®æ—¶å»ºè®®
- ç§»åŠ¨ç«¯éƒ¨ç½²

**é“¾æ¥**: [https://hf.co/Qwen/Qwen3-0.6B](https://hf.co/Qwen/Qwen3-0.6B)

---

#### meta-llama/Llama-3.1-8B-Instruct ğŸŒ å¤šè¯­è¨€

**åŸºæœ¬ä¿¡æ¯**:
- **æ¨¡å‹ ID**: `meta-llama/Llama-3.1-8B-Instruct`
- **ä»»åŠ¡ç±»å‹**: text-generation
- **åº“**: transformers
- **ä¸‹è½½é‡**: 7.2M
- **ç‚¹èµæ•°**: 5397

**ç‰¹ç‚¹**:
- Meta å®˜æ–¹æ¨¡å‹
- æ”¯æŒå¤šè¯­è¨€ï¼ˆè‹±ã€å¾·ã€æ³•ã€æ„ã€è‘¡ã€å°åœ°ã€è¥¿ã€æ³°ï¼‰
- æ€§èƒ½å¼ºå¤§
- ç¤¾åŒºæ”¯æŒå¥½

**ä½¿ç”¨åœºæ™¯**:
- å›½é™…åŒ–éœ€æ±‚
- å¤šè¯­è¨€å¯¹è¯
- è·¨è¯­è¨€ä»»åŠ¡
- ç¿»è¯‘è¾…åŠ©

**é“¾æ¥**: [https://hf.co/meta-llama/Llama-3.1-8B-Instruct](https://hf.co/meta-llama/Llama-3.1-8B-Instruct)

---

#### openai/gpt-oss-20b ğŸ¯ é«˜è´¨é‡

**åŸºæœ¬ä¿¡æ¯**:
- **æ¨¡å‹ ID**: `openai/gpt-oss-20b`
- **ä»»åŠ¡ç±»å‹**: text-generation
- **åº“**: transformers
- **ä¸‹è½½é‡**: 6.1M
- **ç‚¹èµæ•°**: 4309
- **è®¸å¯è¯**: Apache 2.0

**ç‰¹ç‚¹**:
- OpenAI å¼€æºå®ç°
- å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ20B å‚æ•°ï¼‰
- ç”Ÿæˆè´¨é‡é«˜
- æ”¯æŒ 8-bit é‡åŒ–

**ä½¿ç”¨åœºæ™¯**:
- é«˜è´¨é‡å†…å®¹ç”Ÿæˆ
- å¤æ‚ä»»åŠ¡å¤„ç†
- åˆ›æ„å†™ä½œ
- æ·±åº¦åˆ†æ

**é“¾æ¥**: [https://hf.co/openai/gpt-oss-20b](https://hf.co/openai/gpt-oss-20b)

---

#### Qwen/Qwen2.5-VL-3B-Instruct ğŸ–¼ï¸ å¤šæ¨¡æ€

**åŸºæœ¬ä¿¡æ¯**:
- **æ¨¡å‹ ID**: `Qwen/Qwen2.5-VL-3B-Instruct`
- **ä»»åŠ¡ç±»å‹**: image-text-to-text
- **åº“**: transformers
- **ä¸‹è½½é‡**: 21.6M
- **ç‚¹èµæ•°**: 603

**ç‰¹ç‚¹**:
- æ”¯æŒå›¾åƒå’Œæ–‡æœ¬è¾“å…¥
- è§†è§‰ç†è§£èƒ½åŠ›å¼º
- å¤šæ¨¡æ€å¯¹è¯
- å›¾åƒæè¿°å’Œåˆ†æ

**ä½¿ç”¨åœºæ™¯**:
- å›¾åƒç†è§£å’Œæè¿°
- è§†è§‰é—®ç­”
- å›¾è¡¨åˆ†æ
- å¤šæ¨¡æ€å¯¹è¯

**é“¾æ¥**: [https://hf.co/Qwen/Qwen2.5-VL-3B-Instruct](https://hf.co/Qwen/Qwen2.5-VL-3B-Instruct)

---

### å…¶ä»–æ¨èæ¨¡å‹

| æ¨¡å‹ ID | ç±»å‹ | ä¸‹è½½é‡ | ç‰¹ç‚¹ | é“¾æ¥ |
|---------|------|--------|------|------|
| Qwen/Qwen2.5-3B-Instruct | text-generation | 10.5M | å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ | [æŸ¥çœ‹](https://hf.co/Qwen/Qwen2.5-3B-Instruct) |
| Qwen/Qwen2.5-1.5B-Instruct | text-generation | 6.4M | è¶…è½»é‡çº§ | [æŸ¥çœ‹](https://hf.co/Qwen/Qwen2.5-1.5B-Instruct) |
| Qwen/Qwen3-4B | text-generation | 5.2M | ä¸­ç­‰è§„æ¨¡ | [æŸ¥çœ‹](https://hf.co/Qwen/Qwen3-4B) |
| openai-community/gpt2 | text-generation | 7.4M | ç»å…¸æ¨¡å‹ | [æŸ¥çœ‹](https://hf.co/openai-community/gpt2) |

## ç›¸å…³ Spaces

### HLE Leaderboard for Agents with Tools

**åŸºæœ¬ä¿¡æ¯**:
- **Space ID**: `zoom-ai/hle-leaderboard`
- **ä½œè€…**: zoom-ai
- **ç±»åˆ«**: Text Analysis
- **ç‚¹èµæ•°**: 5
- **ç›¸å…³æ€§**: 73.2%

**æè¿°**: Humanity's Last Exam Leaderboard for LLM Agents with Tools

**ç”¨é€”**:
- äº†è§£ LLM ä»£ç†å·¥å…·çš„æ€§èƒ½æ’è¡Œ
- å‚è€ƒè¯„ä¼°æ ‡å‡†
- å­¦ä¹ æœ€ä½³å®è·µ

**é“¾æ¥**: [https://hf.co/spaces/zoom-ai/hle-leaderboard](https://hf.co/spaces/zoom-ai/hle-leaderboard)

---

### GroqChatBot

**åŸºæœ¬ä¿¡æ¯**:
- **Space ID**: `hassan773/SageBot`
- **ä½œè€…**: hassan773
- **ç±»åˆ«**: Chatbots
- **ç‚¹èµæ•°**: 4
- **ç›¸å…³æ€§**: 70.9%

**æè¿°**: èŠå¤©æœºå™¨äººåŠ©æ‰‹å®ç°

**ç”¨é€”**:
- å‚è€ƒèŠå¤©ç•Œé¢è®¾è®¡
- å­¦ä¹ å¯¹è¯æµç¨‹
- UI/UX çµæ„Ÿ

**é“¾æ¥**: [https://hf.co/spaces/hassan773/SageBot](https://hf.co/spaces/hassan773/SageBot)

---

### First Agent Template

**åŸºæœ¬ä¿¡æ¯**:
- **Space ID**: `ATLearner/AT_First_agent_template`
- **ä½œè€…**: ATLearner
- **ç±»åˆ«**: Code Generation
- **ç‚¹èµæ•°**: 1
- **ç›¸å…³æ€§**: 55.8%

**æè¿°**: ä½¿ç”¨ AI ä»£ç†ç”Ÿæˆè‡ªå®šä¹‰ä»£ç è§£å†³æ–¹æ¡ˆ

**ç”¨é€”**:
- ä»£ç ç”Ÿæˆå‚è€ƒ
- ä»£ç†æ¨¡æ¿å­¦ä¹ 
- å·¥ä½œæµè®¾è®¡

**é“¾æ¥**: [https://hf.co/spaces/ATLearner/AT_First_agent_template](https://hf.co/spaces/ATLearner/AT_First_agent_template)

---

### TraceMind AI

**åŸºæœ¬ä¿¡æ¯**:
- **Space ID**: `MCP-1st-Birthday/TraceMind`
- **ä½œè€…**: MCP-1st-Birthday
- **ç±»åˆ«**: Data Visualization
- **ç‚¹èµæ•°**: 21
- **ç›¸å…³æ€§**: 32.0%

**æè¿°**: åŸºäº MCP çš„ AI ä»£ç†è¯„ä¼°ç³»ç»Ÿ

**ç”¨é€”**:
- MCP é›†æˆå‚è€ƒ
- ä»£ç†è¯„ä¼°æ–¹æ³•
- å¯è§†åŒ–è®¾è®¡

**é“¾æ¥**: [https://hf.co/spaces/MCP-1st-Birthday/TraceMind](https://hf.co/spaces/MCP-1st-Birthday/TraceMind)

---

### AgentReview

**åŸºæœ¬ä¿¡æ¯**:
- **Space ID**: `Ahren09/AgentReview`
- **ä½œè€…**: Ahren09
- **ç±»åˆ«**: Text Generation
- **ç‚¹èµæ•°**: 13
- **ä¼šè®®**: EMNLP 2024

**æè¿°**: ä»£ç†è¯„å®¡ç³»ç»Ÿ

**ç”¨é€”**:
- å­¦æœ¯ç ”ç©¶å‚è€ƒ
- è¯„å®¡æµç¨‹è®¾è®¡
- è´¨é‡æ§åˆ¶

**é“¾æ¥**: [https://hf.co/spaces/Ahren09/AgentReview](https://hf.co/spaces/Ahren09/AgentReview)

## æ¨èæ•°æ®é›†

### google-research-datasets/mbpp

**åŸºæœ¬ä¿¡æ¯**:
- **æ•°æ®é›† ID**: `google-research-datasets/mbpp`
- **ä¸‹è½½é‡**: 1.2M
- **ç‚¹èµæ•°**: 215
- **è®¸å¯è¯**: CC-BY-4.0

**æè¿°**: Mostly Basic Python Problems (MBPP) - åŒ…å«çº¦ 1,000 ä¸ªä¼—åŒ…çš„ Python ç¼–ç¨‹é—®é¢˜

**ç”¨é€”**:
- ä»£ç ç”Ÿæˆè®­ç»ƒ
- ç¼–ç¨‹èƒ½åŠ›è¯„ä¼°
- åŸºå‡†æµ‹è¯•

**é“¾æ¥**: [https://hf.co/datasets/google-research-datasets/mbpp](https://hf.co/datasets/google-research-datasets/mbpp)

---

### deepmind/code_contests

**åŸºæœ¬ä¿¡æ¯**:
- **æ•°æ®é›† ID**: `deepmind/code_contests`
- **ä¸‹è½½é‡**: 1.2M
- **ç‚¹èµæ•°**: 211
- **è®¸å¯è¯**: CC-BY-4.0

**æè¿°**: ç«èµ›ç¼–ç¨‹æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒ AlphaCode

**ç”¨é€”**:
- é«˜çº§ä»£ç ç”Ÿæˆ
- ç®—æ³•é—®é¢˜æ±‚è§£
- æ¨¡å‹è®­ç»ƒ

**é“¾æ¥**: [https://hf.co/datasets/deepmind/code_contests](https://hf.co/datasets/deepmind/code_contests)

---

### NTU-NLP-sg/xCodeEval

**åŸºæœ¬ä¿¡æ¯**:
- **æ•°æ®é›† ID**: `NTU-NLP-sg/xCodeEval`
- **ä¸‹è½½é‡**: 1.3M
- **ç‚¹èµæ•°**: 57
- **è®¸å¯è¯**: CC-BY-4.0

**æè¿°**: å¤šè¯­è¨€ä»£ç è¯„ä¼°æ•°æ®é›†

**ç”¨é€”**:
- è·¨è¯­è¨€ä»£ç ç”Ÿæˆ
- å¤šè¯­è¨€æ”¯æŒæµ‹è¯•
- ç¿»è¯‘è¯„ä¼°

**é“¾æ¥**: [https://hf.co/datasets/NTU-NLP-sg/xCodeEval](https://hf.co/datasets/NTU-NLP-sg/xCodeEval)

---

### huggingface/documentation-images

**åŸºæœ¬ä¿¡æ¯**:
- **æ•°æ®é›† ID**: `huggingface/documentation-images`
- **ä¸‹è½½é‡**: 1.9M
- **ç‚¹èµæ•°**: 103
- **è®¸å¯è¯**: CC-BY-NC-SA-4.0

**æè¿°**: HuggingFace æ–‡æ¡£ä¸­ä½¿ç”¨çš„å›¾åƒé›†åˆ

**ç”¨é€”**:
- UI è®¾è®¡å‚è€ƒ
- å›¾æ ‡å’Œæ’å›¾
- æ–‡æ¡£ç´ æ

**é“¾æ¥**: [https://hf.co/datasets/huggingface/documentation-images](https://hf.co/datasets/huggingface/documentation-images)

## ç›¸å…³ç ”ç©¶è®ºæ–‡

### Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention

**åŸºæœ¬ä¿¡æ¯**:
- **å‘å¸ƒæ—¥æœŸ**: 2026-01-10
- **ä½œè€…**: Luis Rosario Freytes
- **è®ºæ–‡ ID**: 2601.11618

**æ‘˜è¦**: é€šè¿‡å››ä¸ªç‹¬ç«‹ç»„ä»¶å®šä¹‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°åŸåˆ™æ€§çš„æ³¨æ„åŠ›æ¶æ„è®¾è®¡å’Œåˆ†æ

**å…³é”®è¯**: attention layer, carrier, evidence-kernel rule, probe family, anchor/update rule

**ç›¸å…³æ€§**: ç†è§£ Transformer æ³¨æ„åŠ›æœºåˆ¶çš„æœ€æ–°ç†è®º

**é“¾æ¥**: [https://hf.co/papers/2601.11618](https://hf.co/papers/2601.11618)

---

### The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit

**åŸºæœ¬ä¿¡æ¯**:
- **å‘å¸ƒæ—¥æœŸ**: 2023-06-30
- **ä½œè€…**: Lorenzo Noci, Chuning Li, Mufan Bill Li, Bobby He, Thomas Hofmann, Chris Maddison, Daniel M. Roy
- **è®ºæ–‡ ID**: 2306.17759
- **ç‚¹èµæ•°**: 4

**æ‘˜è¦**: æ”¹è¿›çš„ Softmax æ³¨æ„åŠ›æ¨¡å‹ï¼Œåœ¨æ— é™æ·±åº¦å’Œå®½åº¦ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„åæ–¹å·®ç»“æ„å’Œç¨³å®šæ€§

**å…³é”®è¯**: covariance matrix, representations, trainability, Transformers

**ç›¸å…³æ€§**: æ¨¡å‹ç¨³å®šæ€§å’Œå¯è®­ç»ƒæ€§ç ”ç©¶

**é“¾æ¥**: [https://hf.co/papers/2306.17759](https://hf.co/papers/2306.17759)

---

### AttentionViz: A Global View of Transformer Attention

**åŸºæœ¬ä¿¡æ¯**:
- **å‘å¸ƒæ—¥æœŸ**: 2023-05-04
- **ä½œè€…**: Catherine Yeh, Yida Chen, Aoyu Wu, Cynthia Chen, Fernanda ViÃ©gas, Martin Wattenberg
- **è®ºæ–‡ ID**: 2305.03210
- **ç‚¹èµæ•°**: 1
- **è®¨è®º**: 2 æ¡è¯„è®º

**æ‘˜è¦**: äº¤äº’å¼å¯è§†åŒ–å·¥å…·ï¼Œç”¨äºåˆ†æ Transformer æ¨¡å‹ä¸­çš„å…¨å±€æ³¨æ„åŠ›æ¨¡å¼

**å…³é”®è¯**: transformer models, self-attention mechanism, interactive visualization tool

**ç›¸å…³æ€§**: æ¨¡å‹å¯è§£é‡Šæ€§å’Œå¯è§†åŒ–

**é“¾æ¥**: [https://hf.co/papers/2305.03210](https://hf.co/papers/2305.03210)

## MCP å·¥å…·åˆ—è¡¨

é€šè¿‡ Hugging Face MCP æœåŠ¡å™¨å¯ç”¨çš„å·¥å…·ï¼š

### æœç´¢å·¥å…·

1. **model_search** - æœç´¢æœºå™¨å­¦ä¹ æ¨¡å‹
   - å‚æ•°ï¼šquery, author, task, library, sort, limit
   - è¿”å›ï¼šæ¨¡å‹åˆ—è¡¨åŠè¯¦ç»†ä¿¡æ¯

2. **dataset_search** - æœç´¢æ•°æ®é›†
   - å‚æ•°ï¼šquery, author, tags, sort, limit
   - è¿”å›ï¼šæ•°æ®é›†åˆ—è¡¨åŠè¯¦ç»†ä¿¡æ¯

3. **paper_search** - æœç´¢ç ”ç©¶è®ºæ–‡
   - å‚æ•°ï¼šquery, results_limit, concise_only
   - è¿”å›ï¼šè®ºæ–‡åˆ—è¡¨åŠæ‘˜è¦

4. **space_search** - æœç´¢ Hugging Face Spaces
   - å‚æ•°ï¼šquery, limit, mcp
   - è¿”å›ï¼šSpace åˆ—è¡¨åŠç›¸å…³ä¿¡æ¯

### ä¿¡æ¯è·å–

5. **hub_repo_details** - è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯
   - å‚æ•°ï¼šrepo_ids, repo_type
   - è¿”å›ï¼šä»“åº“å®Œæ•´ä¿¡æ¯

6. **hf_doc_search** - æœç´¢ Hugging Face æ–‡æ¡£
   - å‚æ•°ï¼šquery, product
   - è¿”å›ï¼šæ–‡æ¡£æœç´¢ç»“æœ

7. **hf_doc_fetch** - è·å–æ–‡æ¡£å†…å®¹
   - å‚æ•°ï¼šdoc_url, offset
   - è¿”å›ï¼šæ–‡æ¡£å®Œæ•´å†…å®¹

### ç”Ÿæˆå·¥å…·

8. **gr1_z_image_turbo_generate** - ç”Ÿæˆå›¾åƒ
   - å‚æ•°ï¼šprompt, resolution, seed, steps, shift, random_seed
   - è¿”å›ï¼šç”Ÿæˆçš„å›¾åƒ

### è®¤è¯

9. **hf_whoami** - æŸ¥çœ‹è®¤è¯çŠ¶æ€
   - å‚æ•°ï¼šæ— 
   - è¿”å›ï¼šç”¨æˆ·ä¿¡æ¯å’Œè®¤è¯æŒ‡å—

## ä½¿ç”¨å»ºè®®

### æ¨¡å‹é€‰æ‹©æŒ‡å—

**åœºæ™¯ä¸€ï¼šå®æ—¶å¯¹è¯**
- æ¨èï¼šQwen/Qwen3-0.6B
- åŸå› ï¼šè½»é‡å¿«é€Ÿï¼Œé€‚åˆå®æ—¶äº¤äº’

**åœºæ™¯äºŒï¼šå¤æ‚ä»»åŠ¡**
- æ¨èï¼šQwen/Qwen2.5-7B-Instruct æˆ– openai/gpt-oss-20b
- åŸå› ï¼šæ€§èƒ½å¼ºå¤§ï¼Œç†è§£èƒ½åŠ›å¥½

**åœºæ™¯ä¸‰ï¼šå¤šè¯­è¨€æ”¯æŒ**
- æ¨èï¼šmeta-llama/Llama-3.1-8B-Instruct
- åŸå› ï¼šåŸç”Ÿæ”¯æŒå¤šç§è¯­è¨€

**åœºæ™¯å››ï¼šå›¾åƒç†è§£**
- æ¨èï¼šQwen/Qwen2.5-VL-3B-Instruct
- åŸå› ï¼šå¤šæ¨¡æ€èƒ½åŠ›

### æˆæœ¬ä¼˜åŒ–

**ç­–ç•¥ä¸€ï¼šæ¨¡å‹åˆ†å±‚**
- ç®€å•ä»»åŠ¡ä½¿ç”¨å°æ¨¡å‹ï¼ˆ0.6B-1.5Bï¼‰
- å¤æ‚ä»»åŠ¡ä½¿ç”¨å¤§æ¨¡å‹ï¼ˆ7B-20Bï¼‰
- æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€é€‰æ‹©

**ç­–ç•¥äºŒï¼šç¼“å­˜æœºåˆ¶**
- ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ
- å‡å°‘é‡å¤ API è°ƒç”¨
- è®¾ç½®åˆç†çš„ç¼“å­˜è¿‡æœŸæ—¶é—´

**ç­–ç•¥ä¸‰ï¼šæ‰¹å¤„ç†**
- åˆå¹¶ç›¸ä¼¼è¯·æ±‚
- æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
- å‡å°‘ API è°ƒç”¨æ¬¡æ•°

### æœ€ä½³å®è·µ

**å®è·µä¸€ï¼šé”™è¯¯å¤„ç†**
- å®ç°é‡è¯•æœºåˆ¶
- å¤„ç†é€Ÿç‡é™åˆ¶
- æä¾›é™çº§æ–¹æ¡ˆ

**å®è·µäºŒï¼šç›‘æ§å’Œæ—¥å¿—**
- è®°å½•æ‰€æœ‰ API è°ƒç”¨
- è¿½è¸ªå“åº”æ—¶é—´
- åˆ†æä½¿ç”¨æ¨¡å¼

**å®è·µä¸‰ï¼šå®‰å…¨æ€§**
- ä¿æŠ¤ API Token
- ä½¿ç”¨ç¯å¢ƒå˜é‡
- å®šæœŸè½®æ¢å¯†é’¥

## æ›´æ–°è®°å½•

### 2026-02-07
- âœ… åˆå§‹ç‰ˆæœ¬åˆ›å»º
- âœ… æ·»åŠ æ¨èæ¨¡å‹åˆ—è¡¨
- âœ… æ·»åŠ ç›¸å…³ Spaces
- âœ… æ·»åŠ æ•°æ®é›†æ¸…å•
- âœ… æ·»åŠ ç ”ç©¶è®ºæ–‡
- âœ… æ·»åŠ  MCP å·¥å…·åˆ—è¡¨
- âœ… æ·»åŠ ä½¿ç”¨å»ºè®®

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026-02-07  
**ç»´æŠ¤è€…**: AI Team  
**ä¸‹æ¬¡å®¡æŸ¥**: 2026-02-14
